{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8d465fa-a6b1-4843-b820-b7687d0e1a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e0549b2-922d-4d1e-8bed-f44d8d3e1e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For out experiments we use 3 main dataset and 1 sanity dataset. ( ADD MORE LATER :MABON)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc8749e-c6ee-4ec1-b5df-eafcdd48fd60",
   "metadata": {},
   "source": [
    "# Processing For BaseLine "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65084592-7ff2-4efc-95ef-c06b0de9165c",
   "metadata": {},
   "source": [
    "## Kaggle\n",
    "Link: https://www.kaggle.com/datasets/mrmorj/hate-speech-and-offensive-language-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ddbab5-a997-4ce0-9182-b67e1b8f2ac3",
   "metadata": {},
   "source": [
    "### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adad431e-f128-467b-80a7-15463b98c4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New CSV 'Kaggle.csv' generated with columns: sentence, label\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('dataset/Kaggle.csv')\n",
    "# Create a new label column: toxic (class 0 or 1) or non-toxic (class 2)\n",
    "df['label'] = df['class'].apply(lambda x: 'toxic' if x in [0, 1] else 'non-toxic')\n",
    "new_df = df[['tweet', 'label']].rename(columns={'tweet': 'sentence'})\n",
    "\n",
    "# Save to a new CSV file\n",
    "new_df.to_csv('dataset/CleanedBaseline/Kaggle.csv', index=False)\n",
    "\n",
    "print(\"New CSV 'Kaggle.csv' generated with columns: sentence, label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e934d6-8bc6-4f67-adcf-0e0620dcb140",
   "metadata": {},
   "source": [
    "### Data Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c65fa360-08da-4da1-b630-249bad96d8a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dataset Statistics ===\n",
      "Total number of rows: 24783\n",
      "\n",
      "Label distribution (counts):\n",
      "label\n",
      "toxic        20620\n",
      "non-toxic     4163\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label distribution (percentages):\n",
      "label\n",
      "toxic        83.2\n",
      "non-toxic    16.8\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Sentence length (characters) statistics:\n",
      "count    24783.00\n",
      "mean        85.44\n",
      "std         41.55\n",
      "min          5.00\n",
      "25%         52.00\n",
      "50%         81.00\n",
      "75%        119.00\n",
      "max        754.00\n",
      "Name: char_length, dtype: float64\n",
      "\n",
      "Sentence length (words) statistics:\n",
      "count    24783.00\n",
      "mean        14.12\n",
      "std          6.83\n",
      "min          1.00\n",
      "25%          9.00\n",
      "50%         13.00\n",
      "75%         19.00\n",
      "max         52.00\n",
      "Name: word_count, dtype: float64\n",
      "\n",
      "Number of unique sentences: 24783\n",
      "Number of duplicate sentences: 0\n"
     ]
    }
   ],
   "source": [
    "# Compute statistics\n",
    "print(\"=== Dataset Statistics ===\")\n",
    "\n",
    "# 1. Total number of rows\n",
    "print(f\"Total number of rows: {len(new_df)}\")\n",
    "\n",
    "# 2. Label distribution\n",
    "label_counts = new_df['label'].value_counts()\n",
    "label_percentages = new_df['label'].value_counts(normalize=True) * 100\n",
    "print(\"\\nLabel distribution (counts):\")\n",
    "print(label_counts)\n",
    "print(\"\\nLabel distribution (percentages):\")\n",
    "print(label_percentages.round(2))\n",
    "\n",
    "# 3. Sentence length statistics (character count)\n",
    "new_df['char_length'] = new_df['sentence'].apply(len)\n",
    "char_stats = new_df['char_length'].describe()\n",
    "print(\"\\nSentence length (characters) statistics:\")\n",
    "print(char_stats.round(2))\n",
    "\n",
    "# 4. Sentence length statistics (word count)\n",
    "new_df['word_count'] = new_df['sentence'].apply(lambda x: len(x.split()))\n",
    "word_stats = new_df['word_count'].describe()\n",
    "print(\"\\nSentence length (words) statistics:\")\n",
    "print(word_stats.round(2))\n",
    "\n",
    "# 5. Unique sentences\n",
    "unique_sentences = new_df['sentence'].nunique()\n",
    "print(f\"\\nNumber of unique sentences: {unique_sentences}\")\n",
    "print(f\"Number of duplicate sentences: {len(new_df) - unique_sentences}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87502e38-4c00-48cb-a897-6762bc37f65f",
   "metadata": {},
   "source": [
    "## UCB DATASET\n",
    "Link: https://huggingface.co/datasets/ucberkeley-dlab/measuring-hate-speech\n",
    "@article{kennedy2020constructing,\n",
    "  title={Constructing interval variables via faceted Rasch measurement and multitask deep learning: a hate speech application},\n",
    "  author={Kennedy, Chris J and Bacon, Geoff and Sahn, Alexander and von Vacano, Claudia},\n",
    "  journal={arXiv preprint arXiv:2009.10277},\n",
    "  year={2020}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7946b8-10f4-4975-a4f5-0c5427e99938",
   "metadata": {},
   "source": [
    "### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d0baf6a-c6c6-4f4b-a2d9-8da4e900a441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New CSV 'UCB.csv' generated with columns: sentence, label\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.load_dataset('ucberkeley-dlab/measuring-hate-speech')   \n",
    "df = dataset['train'].to_pandas()\n",
    "\n",
    "# Define toxic label: toxic if any of insult, humiliate, dehumanize, or violence > 0\n",
    "df['label'] = df[['insult', 'humiliate', 'dehumanize', 'violence']].apply(\n",
    "    lambda x: 'toxic' if any(x > 0) else 'non-toxic', axis=1\n",
    ")\n",
    "\n",
    "df['sentence'] = df['comment_id'].apply(lambda x: f\"Comment_{x}\")\n",
    "\n",
    "# Select only sentence and label columns\n",
    "new_df = df[['sentence', 'label']]\n",
    "# Save to a new CSV file\n",
    "new_df.to_csv('dataset/CleanedBaseline/UCB.csv', index=False)\n",
    "\n",
    "print(\"New CSV 'UCB.csv' generated with columns: sentence, label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcd7f229-53d9-49ce-a805-1e57c9b2e43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dataset/RawUCB.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaef5884-a481-4f7b-9ff7-926ad0a3ef2d",
   "metadata": {},
   "source": [
    "### Data Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "234d4070-282d-4fc2-b26d-53b257cf9e80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Dataset Statistics ===\n",
      "Total number of rows: 135556\n",
      "\n",
      "Label distribution (counts):\n",
      "label\n",
      "toxic        120025\n",
      "non-toxic     15531\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label distribution (percentages):\n",
      "label\n",
      "toxic        88.54\n",
      "non-toxic    11.46\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Sentence length (characters) statistics:\n",
      "count    135556.00\n",
      "mean         12.85\n",
      "std           0.41\n",
      "min           9.00\n",
      "25%          13.00\n",
      "50%          13.00\n",
      "75%          13.00\n",
      "max          13.00\n",
      "Name: char_length, dtype: float64\n",
      "\n",
      "Sentence length (words) statistics:\n",
      "count    135556.0\n",
      "mean          1.0\n",
      "std           0.0\n",
      "min           1.0\n",
      "25%           1.0\n",
      "50%           1.0\n",
      "75%           1.0\n",
      "max           1.0\n",
      "Name: word_count, dtype: float64\n",
      "\n",
      "Number of unique sentences: 39565\n",
      "Number of duplicate sentences: 95991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47424/769326749.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['char_length'] = new_df['sentence'].apply(len)\n",
      "/tmp/ipykernel_47424/769326749.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['word_count'] = new_df['sentence'].apply(lambda x: len(x.split()))\n"
     ]
    }
   ],
   "source": [
    "# Compute statistics\n",
    "print(\"\\n=== Dataset Statistics ===\")\n",
    "\n",
    "# 1. Total number of rows\n",
    "print(f\"Total number of rows: {len(new_df)}\")\n",
    "\n",
    "# 2. Label distribution\n",
    "label_counts = new_df['label'].value_counts()\n",
    "label_percentages = new_df['label'].value_counts(normalize=True) * 100\n",
    "print(\"\\nLabel distribution (counts):\")\n",
    "print(label_counts)\n",
    "print(\"\\nLabel distribution (percentages):\")\n",
    "print(label_percentages.round(2))\n",
    "\n",
    "# 3. Sentence length statistics (character count)\n",
    "new_df['char_length'] = new_df['sentence'].apply(len)\n",
    "char_stats = new_df['char_length'].describe()\n",
    "print(\"\\nSentence length (characters) statistics:\")\n",
    "print(char_stats.round(2))\n",
    "\n",
    "# 4. Sentence length statistics (word count)\n",
    "new_df['word_count'] = new_df['sentence'].apply(lambda x: len(x.split()))\n",
    "word_stats = new_df['word_count'].describe()\n",
    "print(\"\\nSentence length (words) statistics:\")\n",
    "print(word_stats.round(2))\n",
    "\n",
    "# 5. Unique sentences\n",
    "unique_sentences = new_df['sentence'].nunique()\n",
    "print(f\"\\nNumber of unique sentences: {unique_sentences}\")\n",
    "print(f\"Number of duplicate sentences: {len(new_df) - unique_sentences}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3146ff43-5a7b-4c0b-ac56-276fd9db6748",
   "metadata": {},
   "source": [
    "## Convabuse\n",
    "Link: https://github.com/amandacurry/convabuse\n",
    "@inproceedings{cercas-curry-etal-2021-convabuse,\n",
    "title = \"{C}onv{A}buse: Data, Analysis, and Benchmarks for Nuanced Abuse Detection in Conversational {AI}\",\n",
    "author = \"Cercas Curry, Amanda and\n",
    "Abercrombie, Gavin and\n",
    "Rieser, Verena\",\n",
    "booktitle = \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\",\n",
    "month = nov,\n",
    "year = \"2021\",\n",
    "address = \"Online and Punta Cana, Dominican Republic\",\n",
    "publisher = \"Association for Computational Linguistics\",\n",
    "url = \"https://aclanthology.org/2021.emnlp-main.587\",\n",
    "doi = \"10.18653/v1/2021.emnlp-main.587\",\n",
    "pages = \"7388--7403\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c660047-0d61-4f0b-aeb3-4a5e34979aa8",
   "metadata": {},
   "source": [
    "### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7cae47c-580a-440f-b57a-8e3ba6bd1cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New CSV 'cleaned_abuse_dataset.csv' generated with columns: sentence, label\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('dataset/ConvAbuseEMNLPfull.csv')\n",
    "# Define toxic label: toxic if is_abuse.1 = 1, else non-toxic\n",
    "df['label'] = df['is_abuse.1'].apply(lambda x: 'toxic' if x == 1 else 'non-toxic')\n",
    "\n",
    "# Select only sentence (user column) and label columns\n",
    "new_df = df[['user', 'label']].rename(columns={'user': 'sentence'})\n",
    "\n",
    "# Save to a new CSV file\n",
    "new_df.to_csv('dataset/CleanedBaseline/Convabuse.csv', index=False)\n",
    "\n",
    "print(\"New CSV 'cleaned_abuse_dataset.csv' generated with columns: sentence, label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acef9ce-5f05-48ef-b360-5bc630f0544a",
   "metadata": {},
   "source": [
    "### Data Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50c7b126-a64a-42e7-887e-4e6f9a280e0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Dataset Statistics ===\n",
      "Total number of rows: 12768\n",
      "\n",
      "Label distribution (counts):\n",
      "label\n",
      "toxic        10068\n",
      "non-toxic     2700\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label distribution (percentages):\n",
      "label\n",
      "toxic        78.85\n",
      "non-toxic    21.15\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Sentence length (characters) statistics:\n",
      "count    12768.00\n",
      "mean        15.99\n",
      "std         21.09\n",
      "min          1.00\n",
      "25%          5.00\n",
      "50%         11.00\n",
      "75%         20.00\n",
      "max        444.00\n",
      "Name: char_length, dtype: float64\n",
      "\n",
      "Sentence length (words) statistics:\n",
      "count    12768.00\n",
      "mean         3.43\n",
      "std          3.93\n",
      "min          1.00\n",
      "25%          1.00\n",
      "50%          3.00\n",
      "75%          4.00\n",
      "max         76.00\n",
      "Name: word_count, dtype: float64\n",
      "\n",
      "Number of unique sentences: 2913\n",
      "Number of duplicate sentences: 9855\n"
     ]
    }
   ],
   "source": [
    "# Compute statistics\n",
    "print(\"\\n=== Dataset Statistics ===\")\n",
    "\n",
    "# 1. Total number of rows\n",
    "print(f\"Total number of rows: {len(new_df)}\")\n",
    "\n",
    "# 2. Label distribution\n",
    "label_counts = new_df['label'].value_counts()\n",
    "label_percentages = new_df['label'].value_counts(normalize=True) * 100\n",
    "print(\"\\nLabel distribution (counts):\")\n",
    "print(label_counts)\n",
    "print(\"\\nLabel distribution (percentages):\")\n",
    "print(label_percentages.round(2))\n",
    "\n",
    "# 3. Sentence length statistics (character count)\n",
    "new_df['char_length'] = new_df['sentence'].apply(len)\n",
    "char_stats = new_df['char_length'].describe()\n",
    "print(\"\\nSentence length (characters) statistics:\")\n",
    "print(char_stats.round(2))\n",
    "\n",
    "# 4. Sentence length statistics (word count)\n",
    "new_df['word_count'] = new_df['sentence'].apply(lambda x: len(x.split()))\n",
    "word_stats = new_df['word_count'].describe()\n",
    "print(\"\\nSentence length (words) statistics:\")\n",
    "print(word_stats.round(2))\n",
    "\n",
    "# 5. Unique sentences\n",
    "unique_sentences = new_df['sentence'].nunique()\n",
    "print(f\"\\nNumber of unique sentences: {unique_sentences}\")\n",
    "print(f\"Number of duplicate sentences: {len(new_df) - unique_sentences}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f0dab6-d87f-4a30-b676-4123e6a88c55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
